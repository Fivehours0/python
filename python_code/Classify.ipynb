{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import struct\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = os.path.join(os.getcwd(), 'datasets')\n",
    "def load_mnist(path, kind):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels.idx1-ubyte'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images.idx3-ubyte'\n",
    "                               % kind)\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II',\n",
    "                                 lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath,\n",
    "                             dtype=np.uint8)\n",
    " \n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII',\n",
    "                                               imgpath.read(16))\n",
    "        images = np.fromfile(imgpath,\n",
    "                             dtype=np.uint8).reshape(len(labels), 784)\n",
    " \n",
    "    return images, labels\n",
    "train_images, train_labels = load_mnist(path, 'train')\n",
    "test_images, test_labels = load_mnist(path, 't10k')\n",
    "\n",
    "\n",
    "'''显示测试集中的一幅图像'''\n",
    "some_data = train_images[40000]\n",
    "some_data_image = some_data.reshape(28, 28)\n",
    "plt.imshow(some_data_image, cmap=plt.cm.binary, interpolation='nearest')  # interpolation差值\n",
    "plt.axis('off')  # 隐藏坐标轴\n",
    "plt.show()\n",
    "\n",
    "\n",
    "'''一些模型对数据的排序敏感，因此在训练之前先将数据的顺序打乱'''\n",
    "shuffle_train_index = np.random.permutation(60000)  # permutation排序\n",
    "x_train, y_train = train_images[shuffle_train_index], train_labels[shuffle_train_index]\n",
    "shuffle_test_index = np.random.permutation(10000)\n",
    "x_test, y_test = test_images[shuffle_test_index], test_labels[shuffle_test_index]\n",
    "\n",
    "'''首先现简化一下问题,只尝试去识别一个数字,比如说,数字 5。这个“数字 5 检测器”就是\n",
    "一个二分类器,能够识别两类别,“是 5”和“非 5”。'''\n",
    "#创建目标向量\n",
    "y_train_5 = (y_train==5)\n",
    "y_test_5 = (y_test==5)\n",
    "\n",
    "'''随机梯度下降分类器SGD，这个分类器有一个好处是能够高效地处理非常大的数据\n",
    "集。这部分原因在于SGD一次只处理一条数据,这也使得 SGD 适合在线学习'''\n",
    "from sklearn.linear_model.stochastic_gradient import SGDClassifier\n",
    "#max_iter指的是最大进行1000次迭代，若要采用minibatch，则可使用parcial_fit而不是fit  \n",
    "#tol  当loss > previous_loss - tol(previous_loss=loss时，即损失保持基本不变)时，停止迭代\n",
    "sgd_clf = SGDClassifier(random_state=42, max_iter=1000, tol=1e-3, n_jobs=-1)\n",
    "sgd_clf.fit(x_train, y_train_5)\n",
    "'''交叉验证'''\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf, x_train, y_train_5, cv=3, scoring='accuracy')  # 交叉验证，k值为3\n",
    "\n",
    "'''以下使用精度，PR曲线，ROC曲线三种方法对分类器的性能进行评估'''\n",
    "'''设计一个非常蠢的分类器，有 90% 的精度。这是因为只有 10% 的图片是数字 5,所以你总是\n",
    "猜测某张图片不是 5,你也会有90%的可能性是对的。当其中一些类比其他类频繁得多，精度不是一个非常准确的指标'''\n",
    "# from sklearn.base import BaseEstimator\n",
    "# class Never5classfier(BaseEstimator):  # 感觉是继承\n",
    "#     def fit(self, X, y=None):   # 直接不进行拟合\n",
    "#         pass\n",
    "#     def predict(self, X):  # 直接返回一个0矩阵\n",
    "#         return np.zeros((len(X), 1), dtype=bool)  # (len(X), 1)为形状，表示返回一个X行1列的0向量\n",
    "# never_5_clf = Never5classfier()\n",
    "# never_5_clf.fit(x_train, y_train_5)\n",
    "# cross_val_score(never_5_clf, x_train, y_train_5, cv=3, scoring='accuracy')\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "#基于交叉验证得到的一组测试值，3折以其他2折作为训练集可预测另外一折的值，并保留。同样的方法可以得到另外两折的值，最后合并输出\n",
    "y_train_pre = cross_val_predict(sgd_clf, x_train, y_train_5, cv=3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''使用混淆矩阵进行模型评估'''\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train_5, y_train_pre)\n",
    "'''计算查准率(准确率)和查全率(召回率)'''\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "#说明了一张5的图片识别为5的概率为73%，而且之检测出‘5’图片的82%\n",
    "precision_score(y_train_5, y_train_pre) # 输出0.7323..\n",
    "recall_score(y_train_5, y_train_pre) # 输出0.8256..\n",
    "f1_score(y_train_5, y_train_pre) # f1值\n",
    "\n",
    "'''不同的项目对查准率和查全率的倾向不同，如根据视频信息查找罪犯，需要较高的查全率'''\n",
    "'''SGDClassifier对于每个样例,它根据决策函数计算分数,如果这个分数大于一个阈值,它会将样例分配给正例,\n",
    "否则它将分配给反例。通过调整thresholds,选出好的准确率/召回率折衷的方法'''\n",
    "#通过set method为decision_function返回训练集的分数\n",
    "y_score = cross_val_predict(sgd_clf, x_train, y_train_5, cv=3, method='decision_function', n_jobs=10)\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "#通过precision_recall_curve返回thresholds变化时的precision and recall，thresholds 大于它为5小于它为非5\n",
    "#然后绘制图像观察recall and precision\n",
    "precision, recall, thresholds = precision_recall_curve(y_train_5, y_score)\n",
    "def plot_precision_recall_vs_threshold(precision, recall, thresholds):\n",
    "    plt.figure()\n",
    "    plt.plot(thresholds, precision[:-1], 'k--', label='precision')\n",
    "    plt.plot(thresholds, recall[:-1], c='red', label='recall')\n",
    "    plt.xlabel('thresholds')\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlim([-10000, 10000])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.show()\n",
    "plot_precision_recall_vs_threshold(precision, recall, thresholds)\n",
    "# '''若想要90%的准确率，可以用下面的方法找到一个阈值，使得准确率达到90%'''\n",
    "y_train_pred_90 = (y_score > 5000)\n",
    "print(precision_score(y_train_5, y_train_pred_90))\n",
    "print(recall_score(y_train_5, y_train_pred_90))  \n",
    "\n",
    "'''PR曲线'''\n",
    "'''选出好的准确率/召回率折衷的方法是直接画出准确率(查准率)对召回率(查全率)的曲线\n",
    "根据实际项目情况进行选择'''\n",
    "def plot_precision_vs_recall():\n",
    "    plt.figure(num=2)  # figure和show函数最好放在函数外避免多次调用。这里不做修改了\n",
    "    plt.plot(recall[:-1], precision[:-1])\n",
    "    plt.xlabel('recall')\n",
    "    plt.ylabel('precision')\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([0,1])   \n",
    "    plt.show()\n",
    "plot_precision_vs_recall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''绘制ROC曲线，在正例较少时PR曲线更优'''\n",
    "'''一个好的分类器的 ROC 曲线应该尽可能向左上角方向靠拢'''\n",
    "'''可以通过比较ROC曲线下的面积(AUC)比较分类器的性能，一个完美的分类器的 AUC 等于 1'''\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_train_5, y_score)\n",
    "def plot_roc(fpr, tpr, label=None, linestyle=None):\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr, tpr, 'red', label=label, linestyle=linestyle)\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.legend(loc = 'best')\n",
    "plt.figure()\n",
    "plot_roc(fpr, tpr, label='sgd')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''通过比较AUC来判断两个分类器的性能'''\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_train_5, y_score)\n",
    "#加入随机森林分类器进行比较,回执roc曲线需要的是样例的分数，一个简单的方法是使用正例的概率当做样例的分数\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_clf = RandomForestClassifier(random_state=42, n_estimators=10, n_jobs=10)\n",
    "'''predict_proba()方法返回一个数组,数组的每一行代表一个样例,\n",
    "每一列代表一个类。数组当中的值的意思是:给定一个样例属于给定类的概率。\n",
    "比如,70%的概率这幅图是数字 5。此例中输出两列，猜测为第一列表示非5的概率,第二列表示为5概率'''\n",
    "y_probas_forest = cross_val_predict(forest_clf, x_train, y_train_5, cv=3, method='predict_proba')\n",
    "y_score_forest = y_probas_forest[:, 1] # 因为要绘制ROC曲线，需要的是样例的分数，以，为5的概率作为分数 \n",
    "fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_5, y_score_forest)\n",
    "'''绘制两个分类器的ROC曲线比较性能'''\n",
    "plt.figure()\n",
    "plot_roc(fpr_forest, tpr_forest, label=\"forest\", linestyle=\"--\")\n",
    "plot_roc(fpr, tpr, label=\"sgd\", linestyle='-')\n",
    "plt.show()\n",
    "roc_auc_score(y_train_5, y_score_forest)  # 随机森林分类器AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''多类分类'''\n",
    "'''现在让我们检测更多的数字,而不仅仅是一个数字 5'''\n",
    "'''一些算法(比如随机森林分类器或者朴素贝叶斯分类器)可以直接处理多类分类问题。其他\n",
    "一些算法(比如 SVM 分类器或者线性分类器)则是严格的二分类器。然后,有许多策略可以\n",
    "让你用二分类器去执行多类分类。\n",
    "“一对所有”(OvA)策略：训练10个二分类器,每一个对应一个数字(探测器 0,探测器 1,探测器 2,以此类推)\n",
    "“一对一”(OvO)策略：一个分类器用来处理数字 0 和数字 1,一个用来处理数字 0 和数字 2,一个用来处理数字 1 和 2,以此类推。'''\n",
    "'''OvO 策略的主要优点是:每个分类器只需要在训练集的部分数据上面进行训\n",
    "练。这部分数据是它所需要区分的那两个类对应的数据。如果有 N 个类。你需要训练N*(N-1)/2个分类器\n",
    "一些算法(比如 SVM 分类器)在训练集的大小上很难扩展,所以对于这些算法,OvO 是比\n",
    "较好的,因为它可以在小的数据集上面可以更多地训练,较之于巨大的数据集而言。但是,\n",
    "对于大部分的二分类器来说,OvA 是更好的选择。'''\n",
    "'''Scikit-Learn 可以探测出你想使用一个二分类器去完成多分类的任务,它会自动地执行OvA'''\n",
    "sgd_clf.fit(x_train, y_train)  # 对所有数据进行训练可以预测所有类，实际上在幕后执行了OVA策略\n",
    "sgd_clf.predict([some_data]) \n",
    "some_data_score = sgd_clf.decision_function([some_data]) # 返回每个类(0-9)的分数\n",
    "sgd_clf.classes_  # 返回目标类别\n",
    "print(np.argmax(some_data_score)) #返回为7,返回分数最大的下标\n",
    "\n",
    "'''基于sgd分类器的OVO策略'''\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "ovo_clf = OneVsOneClassifier(sgd_clf)\n",
    "ovo_clf.fit(x_train, y_train)\n",
    "ovo_clf.predict([some_data])\n",
    "len(ovo_clf.estimators_)  # 返回ovo策略中训练的分类器的个数\n",
    "\n",
    "'''训练随机森林分类器'''\n",
    "forest_clf.fit(x_train, y_train)\n",
    "forest_clf.predict([some_data])\n",
    "forest_clf.predict_proba([some_data])  # 返回样例 是每个类型的 概率\n",
    "'''利用交叉验证评估多分类器'''\n",
    "cross_val_score(sgd_clf, x_train, y_train, cv=3, scoring='accuracy', n_jobs=10)\n",
    "'''可以利用对数据正则化来提升分类器的精度'''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "#x_train.astype拷贝x_train并将他的数据转换为制定类型(np.float64)\n",
    "#fit_transform先进行数据拟合，在进行标准化\n",
    "x_train_scaler = scaler.fit_transform(x_train.astype(np.float64))\n",
    "cross_val_score(sgd_clf, x_train_scaler, y_train, cv=3, scoring='accuracy', n_jobs=10)\n",
    "'''多分类混淆矩阵'''\n",
    "y_train_pred = cross_val_predict(sgd_clf, x_train_scaler, y_train, cv=3)\n",
    "#使用交叉验证的预测值进行评估可以更好的验证模型的泛化能力吧\n",
    "conf_mx = confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(conf_mx, cmap=plt.cm.gray) #将混淆矩阵以图像的方式呈现\n",
    "plt.show()\n",
    "row_sum = conf_mx.sum(axis=1, keepdims=True)  # keepdim保持维度,每行求和\n",
    "norm_conf_mx = conf_mx / row_sum  # 将混淆矩阵的每一个值除以相应类别的图片的总数目，可得到错误率\n",
    "np.fill_diagonal(norm_conf_mx, 0)  # 主对角线变为0,即不管分类正确的\n",
    "#index为真值，column为预测值\n",
    "'''分析混淆矩阵通常可以给你提供深刻的见解去改善你的分类器。回顾这幅图,看样子你应该\n",
    "努力改善分类器在数字 8 和数字 9 上的表现,和纠正 3/5 的混淆。举例子,你可以尝试去收\n",
    "集更多的数据,或者你可以构造新的、有助于分类器的特征。举例子,写一个算法去数闭合\n",
    "的环(比如,数字 8 有两个环,数字 6 有一个, 5 没有)。又或者你可以预处理图片(比\n",
    "如,使用 Scikit-Learn,Pillow, OpenCV)去构造一个模式,比如闭合的环。'''\n",
    "plt.matshow(norm_conf_mx, cmap=plt.cm.gray) # 错误率越高，则亮度越高\n",
    "plt.show()\n",
    "\n",
    "'''显示错误分类的图片进行观察'''\n",
    "cl_a, cl_b = 3, 5\n",
    "X_aa = x_train[(y_train == cl_a) & (y_train_pred == cl_a)] \n",
    "X_ab = x_train[(y_train == cl_a) & (y_train_pred == cl_b)] # 被错误分类为5的3的图片\n",
    "X_ba = x_train[(y_train == cl_b) & (y_train_pred == cl_a)] # 被错误分类为3的5的图片\n",
    "X_bb = x_train[(y_train == cl_b) & (y_train_pred == cl_b)] \n",
    "# ax1 = plt.figure(figsize=())\n",
    "# for i in range(25):\n",
    "#     plt.subplot(5, 5, i+1); plt.imshow(X_aa[i].reshape(28, 28), cmap=plt.cm.binary)\n",
    "#     plt.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "two_dem = X_aa[:25].reshape((25, 28, 28))\n",
    "arr1 = np.c_[two_dem[0], two_dem[1], two_dem[2], two_dem[3], two_dem[4]]\n",
    "arr2 = np.c_[two_dem[5], two_dem[6], two_dem[7], two_dem[8], two_dem[9]]\n",
    "arr3 = np.r_[arr1, arr2]\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(221); \n",
    "plt.imshow(arr3, cmap=plt.cm.binary)\n",
    "plt.subplot(222); \n",
    "plt.subplot(223); \n",
    "plt.subplot(224); \n",
    "plt.show()\n",
    "'''3 和 5 之间的主要差异是连接顶部的线和底部的线的细线的位置。如果你画一个 3,连接处稍\n",
    "微向左偏移,分类器很可能将它分类成 5。反之亦然。换一个说法,这个分类器对于图片的位\n",
    "移和旋转相当敏感。所以,减轻 3/5 混淆的一个方法是对图片进行预处理,确保它们都很好\n",
    "地中心化和不过度旋转。这同样很可能帮助减轻其他类型的错误。'''\n",
    "'''多标签分类P103, 书中举了一个例子，利用y_train_large = y_train >= 7得到y_train大于7的一组布尔量标签，\n",
    "利用y_train_odd = (y_train % 2 == 1)得到y_train中为奇数的一组布尔量标签，利用np.c_合并y_train_large\n",
    "和y_train_odd得到一组标签，将标签作为label，y_train作为样例输入分类器，训练好后，就可以输出x是否大于7和是\n",
    "否为奇数的一组标签，神奇。输入一张图片，观察图片是否具有某个特征（标签），有则为1。'''\n",
    "'''多输出分类P104, 书中举了一个例子，利用noise = rnd.randint(0, 100, (len(X_train), 784))，\n",
    "X_train_mod = X_train + noise，对图像添加噪声，以不带有噪声的图片作为label，带有噪声的图片作为样例输入分\n",
    "类器，经过训练之后，输入一张带有噪声的图片，可输出一张干净的图片，神奇。注意到这个分类器的输出是多标签的(一个像素一个标签)和每个标签可以有多个值\n",
    "(像素强度取值范围从 0 到 255)。所以它是一个多输出分类系统的例子。而多标签分类中，标签的值为0或者1'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
