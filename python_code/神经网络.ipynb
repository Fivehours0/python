{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''阈值逻辑单元(threshold logic unit)，感知器由一层TLU组成，只能解决线性可分类问题。当由多个TLU构成多层感知器(MLU，包含有隐层单元)\n",
    "可以解决单个TLU的局限，反向传播算法中，使用Logistic函数作为激活函数σ(z) = 1 / (1 + exp(–z))代替了阶跃，这是必要的,因为阶跃函数只包\n",
    "含平坦的段,因此没有梯度来工作(梯度下降不能在平面上移动),而 Logistic 函数到处都有一个定义良好的非零导数,允许梯度下降在每个步上取得一些\n",
    "进展。反向传播算法可以与其他激活函数一起使用,而不是 Logistic 函数。另外两个流行的激活函数是:1.双曲正切函数tanh (z) = 2σ(2z) – 1\n",
    "就像 Logistic 函数,它是 S 形的、连续的、可微的,但是它的输出值范围从-1到1(不是在 Logistic 函数的 0 到 1),这往往使每个层的输出在训练\n",
    "开始时或多或少都正则化了(即以 0 为中心)。这常常有助于加快收敛速度。2.ReLU函数:ReLU (z) = max (0, z)。(大于0时相当于y=x)它是连续的,\n",
    "但不幸的是在z=0时不可微(斜率突然改变,这可以使梯度下降反弹)。然而,在实践中,它工作得很好,并且具有快速计算的优点。最重要的是,它没有最大输\n",
    "出值的事实也有助于减少梯度下降期间的一些问题(后期补充)'''\n",
    "#加载数据\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import struct\n",
    "path = os.path.join(os.getcwd(), 'datasets')\n",
    "def load_mnist(path, kind):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels.idx1-ubyte'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images.idx3-ubyte'\n",
    "                               % kind)\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II',\n",
    "                                 lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath,\n",
    "                             dtype=np.uint8)\n",
    " \n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII',\n",
    "                                               imgpath.read(16))\n",
    "        images = np.fromfile(imgpath,\n",
    "                             dtype=np.uint8).reshape(len(labels), 784)\n",
    " \n",
    "    return images, labels\n",
    "train_images, train_labels = load_mnist(path, 'train')\n",
    "test_images, test_labels = load_mnist(path, 't10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''TensorFlow 程序通常分为两部分:第一部分构建计算图谱(这称为构造阶段),第二部分运行它(这是执行阶段)。'''\n",
    "import tensorflow as tf\n",
    "#构建\n",
    "x = tf.Variable(3, name='x')  # 向图谱中创建一个变量初始值为3，名称为x\n",
    "y = tf.Variable(4, name='y')\n",
    "f = x ** 2 * y + y + 2 \n",
    "#运行\n",
    "with tf.Session() as sess:  # 创建一个会话\n",
    "    x.initializer.run() # 初始化变量\n",
    "    y.initializer.run()\n",
    "    result = f.eval() # 求出y的值\n",
    "\n",
    "# way2 也可以使用这种方法来初始化变量\n",
    "# init = tf.global_variables_initializer()\n",
    "# with tf.Session() as sess:\n",
    "#     init.run()\n",
    "#     result = f.eval()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''管理图谱，可同时存在多个图谱，可选择将变量存放于某一个图谱中(一般存放于默认图谱中)'''\n",
    "x1 = tf.Variable(1)\n",
    "graph = tf.Graph()  # 创建一个新的图谱\n",
    "with graph.as_default():  # 将新创建的图谱 暂时 定义为默认图谱\n",
    "    x2 = tf.Variable(2)  # 在默认图谱中创建x2变量\n",
    "x2.graph is graph  # 返回True，说明x2位于graph图谱\n",
    "x2.graph is tf.get_default_graph()  # 返回Flase,graph图谱并不是默认图谱，说明上述操作只是 暂时 定义graph为默认图谱\n",
    "x1.graph is tf.get_default_graph()  # 返回True\n",
    "#tf.reset_default_graph()  # 重置默认图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''变量的生命周期在会话创建时开始，在会话关闭时结束。'''\n",
    "'''tf进行矩阵运算，先创建变量，在创建会话进行计算'''\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "\n",
    "'''constant 创建常量  transpose 矩阵转置 matric_inverse 矩阵求逆 '''\n",
    "'''计算theta=(XT*X)-1 * X * y'''\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)),XT), y)\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "print(theta_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-15-78e63d77156b>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-78e63d77156b>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\u001b[0m\n\u001b[0m                                                                 \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "'''手动操作(不使用API)实现梯度下降'''\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(tf.transpose)\n",
    "#train_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
